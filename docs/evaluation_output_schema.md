# CogniBench Evaluation Output Schema

This document describes the JSONL output schema generated by CogniBench evaluations. Each line in the output file represents a single evaluation record in JSON format.

## Schema Overview

| Field Name                   | Type                 | Description                                                                 |
|------------------------------|----------------------|-----------------------------------------------------------------------------|
| `evaluation_id`              | `string`             | Unique identifier for the evaluation run.                                   |
| `task_id`                    | `string` (optional)  | Identifier for the original task/prompt.                                    |
| `model_id`                   | `string` (optional)  | Identifier for the model that generated the response.                       |
| `response_id`                | `string` (optional)  | Legacy ID of the model response being evaluated.                            |
| `ideal_response_id`          | `string` (optional)  | Legacy ID of the ideal response used.                                       |
| `judge_llm_model`            | `string`             | Name/identifier of the Judge LLM used.                                      |
| `judge_prompt_template_path` | `string`             | Path to the prompt template file used for judging.                          |
| `raw_judge_output`           | `object`             | Raw output received from the Judge LLM.                                     |
| `parsed_rubric_scores`       | `object`             | Parsed rubric scores (criterion â†’ {'score': ..., 'justification': ...}).    |
| `aggregated_score`           | `string` (optional)  | Overall aggregated score ("Pass", "Fail", "Partial").                       |
| `final_answer_verified`      | `boolean` (optional) | Indicates if the final answer matches the correct answer.                   |
| `verification_message`       | `string` (optional)  | Describes the outcome of the verification step.                             |
| `needs_human_review`         | `boolean`            | Indicates if the evaluation requires human review.                          |
| `review_reasons`             | `array[string]`      | Reasons explaining why human review is needed.                              |
| `structured_model_response`  | `object` (optional)  | Structured response from the model (if structuring step was performed).     |
| `structured_ideal_response`  | `object` (optional)  | Structured ideal response (if structuring step was performed).              |
| `parsing_error`              | `string` (optional)  | Error message if judge response parsing failed.                             |
| `human_review_status`        | `string`             | Status of human review ("Needs Review", "Not Required").                    |
| `human_reviewer_id`          | `string` (optional)  | Identifier of the human reviewer (if reviewed).                             |
| `human_review_timestamp`     | `string` (optional)  | Timestamp of human review (ISO 8601 format).                                |
| `human_corrected_scores`     | `object` (optional)  | Corrected rubric scores provided by human reviewer.                         |
| `human_review_comments`      | `string` (optional)  | Comments provided by human reviewer.                                        |
| `created_at`                 | `string`             | Timestamp when the evaluation record was created (ISO 8601 format, UTC).    |

## Example Record

```json
{
  "evaluation_id": "eval_1234567890",
  "task_id": "task_01",
  "model_id": "model_A",
  "judge_llm_model": "gpt-4o",
  "judge_prompt_template_path": "prompts/judging/Math-L1-judge-v1.0.txt",
  "raw_judge_output": {"raw_content": "LLM output text..."},
  "parsed_rubric_scores": {
    "Criterion A": {"score": "Yes", "justification": "Correctly identified."},
    "Criterion B": {"score": "Partial", "justification": "Minor calculation error."}
  },
  "aggregated_score": "Partial",
  "final_answer_verified": true,
  "verification_message": "Verification (SymPy): Match (Extracted: 'x+1', Correct: '1+x').",
  "needs_human_review": true,
  "review_reasons": ["Partial score", "Minor calculation error"],
  "structured_model_response": {"answer": "x+1"},
  "structured_ideal_response": {"answer": "1+x"},
  "parsing_error": null,
  "human_review_status": "Needs Review",
  "human_reviewer_id": null,
  "human_review_timestamp": null,
  "human_corrected_scores": null,
  "human_review_comments": null,
  "created_at": "2025-04-12T17:30:00Z"
}
```

## Notes

- All timestamps are in ISO 8601 format and UTC timezone.
- Optional fields may be `null` or omitted depending on the evaluation context.
- The schema is designed for ease of downstream consumption and integration with analysis tools.