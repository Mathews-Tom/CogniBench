# -*- coding: utf-8 -*-
"""
CogniBench Preprocessing Module.

Provides functions for cleaning and preparing text data before evaluation,
including extracting potential final answers from model responses and
normalizing text formats.

Version: 0.2 (Phase 5 - Code Quality Enhancements)
"""

import logging
import re
import unicodedata
from typing import List, Optional, Pattern

# Setup logger for this module
logger = logging.getLogger(__name__)

# --- Constants ---
# Regular expression patterns to identify potential final answer sections in text.
# These are basic heuristics and may require refinement for different model output styles.
# TODO: Consider making these patterns configurable or using more advanced extraction methods.
# Order matters: More specific patterns should ideally come first.
FINAL_ANSWER_PATTERNS: List[Pattern[str]] = [
    # 1. LaTeX display math: Look for content enclosed in $$...$$
    #    Uses non-greedy matching (.*?) to capture only the content between the first pair.
    re.compile(r"\$\$(.*?)\$\$", re.DOTALL),
    # 2. Keyword-based patterns
    re.compile(r"final answer[:\s]+(.*)", re.IGNORECASE | re.DOTALL),
    re.compile(r"the final answer is[:\s]+(.*)", re.IGNORECASE | re.DOTALL),
    re.compile(r"solution[:\s]+(.*)", re.IGNORECASE | re.DOTALL),  # Added "Solution:"
    re.compile(r"result[:\s]+(.*)", re.IGNORECASE | re.DOTALL),  # Added "Result:"
    # Generic "Answer:" pattern - place last as it's most likely to overmatch
    re.compile(r"(?:^|\.\s|\?\s|\!\s)answer[:\s]+(.*)", re.IGNORECASE | re.DOTALL),
    # Add more patterns here if needed, e.g., for specific formatting like boxes.
]

# Arbitrary length limit for the simple newline heuristic in extract_final_answer.
# Used to prevent capturing large subsequent paragraphs if a newline appears early.
_MAX_LEN_BEFORE_NEWLINE_HEURISTIC: int = 150


def extract_final_answer(response_text: str) -> Optional[str]:
    """
    Attempts to extract the final answer segment from a model's response text.

    Uses a predefined list of regular expression patterns (`FINAL_ANSWER_PATTERNS`)
    to identify keywords indicating a final answer (e.g., "Final Answer:", "Answer:").
    It returns the text following the first matched pattern.

    A simple heuristic is applied to truncate the extracted text at the first
    newline character if it occurs within a certain limit (`_MAX_LEN_BEFORE_NEWLINE_HEURISTIC`),
    aiming to isolate the answer itself from subsequent explanations.

    Note:
        This function relies on simple string patterns and heuristics. It may fail
        if the model uses different phrasing, complex formatting, or does not
        explicitly label the final answer. More robust methods (e.g., advanced
        regex, NLP techniques, dedicated LLM calls) might be necessary for
        higher accuracy, as mentioned in the enhancement plan.

    Args:
        response_text: The full text content generated by the model.

    Returns:
        The extracted final answer as a string, stripped of leading/trailing
        whitespace, or None if no pattern matches or the input is empty.
    """
    if not response_text:
        return None

    # Iterate through patterns to find the first match
    # Check patterns in order
    for i, pattern in enumerate(FINAL_ANSWER_PATTERNS):
        match = pattern.search(response_text)
        if match:
            # Extract the matched group (group 1 for keyword patterns, group 1 for $$)
            extracted: str = match.group(1).strip()

            # If the pattern was the LaTeX one ($$), we likely want the whole matched content.
            # For keyword patterns, apply the newline heuristic.
            is_latex_pattern = (
                pattern.pattern == r"\$\$(.*?)\$\$"
            )  # Check if it's the LaTeX pattern

            if not is_latex_pattern:
                # Apply heuristic: If a newline appears relatively early, truncate there.
                first_newline_index: int = extracted.find("\n")
                if 0 <= first_newline_index < _MAX_LEN_BEFORE_NEWLINE_HEURISTIC:
                    # Check if the text *after* the newline looks like an explanation
                    potential_explanation = extracted[first_newline_index:].lstrip()
                    if not potential_explanation.lower().startswith(
                        (
                            "therefore",
                            "thus",
                            "hence",
                            "because",
                            "explanation",
                            "note:",
                        )
                    ):
                        logger.debug(
                            "Applying newline truncation heuristic for extracted answer."
                        )
                        extracted = extracted[:first_newline_index].strip()
                    else:
                        logger.debug(
                            "Newline found early, but looks like explanation; not truncating."
                        )

            logger.info(
                "Extracted final answer using pattern index %d: %s", i, pattern.pattern
            )
            # Further cleaning could be added here if needed (e.g., removing "The answer is...")
            return extracted

    # Fallback: Currently, no reliable fallback is implemented if patterns fail.
    # Considering the last line is too naive and often incorrect.

    logger.warning(
        "Could not extract final answer from response using defined patterns."
    )
    return None


def normalize_text_formats(text: Optional[str]) -> Optional[str]:
    """
    Performs basic text normalization on a given string.

    Steps include:
    1.  Unicode Normalization (NFC form).
    2.  Replacing sequences of multiple whitespace characters (spaces, tabs,
        newlines, etc.) with a single space.
    3.  Stripping leading and trailing whitespace from the result.

    Note:
        This function currently does *not* handle specific markup like LaTeX or
        MathML. Such normalization would require dedicated libraries (e.g., SymPy)
        and should be implemented as part of the enhancement plan if needed,
        likely during the answer verification stage in postprocessing rather
        than general text normalization here.

    Args:
        text: The input string to normalize, or None.

    Returns:
        The normalized string, or None if the input `text` was None.
    """
    if text is None:
        return None

    # 1. Unicode normalization (NFC is common, combines characters and accents)
    normalized_text: str = unicodedata.normalize("NFC", text)

    # 2. Replace multiple whitespace characters (space, tab, newline, etc.) with a single space
    whitespace_normalized_text: str = re.sub(r"\s+", " ", normalized_text)

    # 3. Strip leading/trailing whitespace
    stripped_text: str = whitespace_normalized_text.strip()

    return stripped_text


# --- Additional Functionality: LaTeX Math Notation Conversion ---
# Precompiled regex patterns for performance
INLINE_MATH_PATTERN = re.compile(r"(?<!\\)\\\((.+?)\\\)", flags=re.DOTALL)
DISPLAY_MATH_PATTERN = re.compile(r"(?<!\\)\\\[(.+?)\\\]", flags=re.DOTALL)


def convert_math_notation(text: Optional[str]) -> Optional[str]:
    """
    Convert LaTeX math notation to standardized format for Jupyter notebooks or similar environments.

    Args:
        text (str): Input text containing LaTeX math notation.

    Returns:
        str: Text with standardized LaTeX math notation.
    """
    if not text:
        return text

    # Convert inline math \( ... \) to $...$
    text = INLINE_MATH_PATTERN.sub(r"$\1$", text)

    # Convert display math \[ ... \] to $$...$$
    text = DISPLAY_MATH_PATTERN.sub(r"$$\1$$", text)

    return text


if __name__ == "__main__":
    # Setup basic logging for testing if run directly
    logging.basicConfig(level=logging.INFO)
    logger.info("\n--- Testing: Extract Final Answer ---")

    test_cases = {
        "Keyword 'Final Answer'": ("Blah blah. Final Answer: x = 5", "x = 5"),
        "Keyword 'The final answer is' + newline": (
            "Calc y=10. The final answer is: y = 10 \n This is because...",
            "y = 10",
        ),
        "Keyword 'The final answer is' + newline + explanation": (
            "Calc y=10. The final answer is: y = 10 \n Therefore it must be...",
            "y = 10",  # Heuristic should not truncate here
        ),
        "Keyword 'Answer'": ("Let z = 3. Answer: z=3", "z=3"),
        "Keyword 'Solution'": ("The steps lead to Solution: a+b=c", "a+b=c"),
        "Keyword 'Result'": ("After calculation, Result: 123.45", "123.45"),
        "LaTeX $$": ("Some text $$ E=mc^2 $$ and more text.", "E=mc^2"),
        "LaTeX $$ multi-line": (
            "Preamble $$\n a^2 + b^2 = c^2 \n$$ Postamble.",
            "a^2 + b^2 = c^2",
        ),
        "No Keyword": ("The value is approximately 42.", None),
        "Empty Input": ("", None),
        "Keyword only": ("Final Answer:", ""),  # Extracts empty string after colon
        "LaTeX empty": (
            "Text $$ $$ more text.",
            "",
        ),  # Extracts empty string between $$
    }

    for name, (input_text, expected_output) in test_cases.items():
        extracted = extract_final_answer(input_text)
        status = "PASS" if extracted == expected_output else "FAIL"
        logger.info(f"Test '{name}': {status}")
        logger.debug(f"  Input: '{input_text}'")
        logger.info(f"  Output: '{extracted}' (Expected: '{expected_output}')")
        if status == "FAIL":
            logger.error(f"  MISMATCH FOUND for test '{name}'!")

    logger.info("\n--- Testing: Text Normalization ---")
    print("\n--- Text Normalization ---")
    test_norm_1 = "  Extra   spaces\nand\ttabs  "
    test_norm_2 = "Already clean."
    test_norm_3 = None
    print(f"'{test_norm_1}' -> '{normalize_text_formats(test_norm_1)}'")
    print(f"'{test_norm_2}' -> '{normalize_text_formats(test_norm_2)}'")
    print(f"'{test_norm_3}' -> '{normalize_text_formats(test_norm_3)}'")
