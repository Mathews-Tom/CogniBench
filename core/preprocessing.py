# -*- coding: utf-8 -*-
"""
CogniBench Preprocessing Module.

Provides functions for cleaning and preparing text data before evaluation,
including extracting potential final answers from model responses and
normalizing text formats.

Version: 0.2 (Phase 5 - Code Quality Enhancements)
"""

import json
import logging
import re
import unicodedata
from typing import List, Optional, Pattern

# Setup logger for this module
logger = logging.getLogger(__name__)

def safe_json_parse(json_string: str) -> Optional[dict]:
    """
    Safely parse a JSON string, handling empty or malformed inputs gracefully.

    Args:
        json_string (str): The JSON string to parse.

    Returns:
        Optional[dict]: Parsed JSON object if successful, None otherwise.
    """
    try:
        if not json_string.strip():
            raise ValueError("Empty JSON string")
        return json.loads(json_string)
    except json.JSONDecodeError as e:
        logger.warning(f"JSON parsing failed: {e.msg} at line {e.lineno} column {e.colno}")
        return None
    except ValueError as e:
        logger.warning(f"JSON parsing failed: {str(e)}")
        return None

# --- Constants ---
# Regular expression patterns to identify potential final answer sections in text.
# These are basic heuristics and may require refinement for different model output styles.
# TODO: Consider making these patterns configurable or using more advanced extraction methods.
# Order matters: More specific patterns should ideally come first.
FINAL_ANSWER_PATTERNS: List[Pattern[str]] = [
    # 1. LaTeX display math: Look for content enclosed in $$...$$
    re.compile(r"\$\$(.*?)\$\$", re.DOTALL),
    # 2. LaTeX boxed notation
    re.compile(r"\\boxed\{(.*?)\}", re.DOTALL),
    # 3. Keyword-based patterns
    re.compile(r"\*\*Exact Answer:\*\*\s*(.*)", re.IGNORECASE | re.DOTALL),
    re.compile(r"\*\*Conclusion:\*\*\s*(.*)", re.IGNORECASE | re.DOTALL),
    re.compile(r"\*\*Answer:\*\*\s*(.*)", re.IGNORECASE | re.DOTALL),
    re.compile(r"final answer[:\s]+(.*)", re.IGNORECASE | re.DOTALL),
    re.compile(r"the final answer is[:\s]+(.*)", re.IGNORECASE | re.DOTALL),
    re.compile(r"solution[:\s]+(.*)", re.IGNORECASE | re.DOTALL),
    re.compile(r"result[:\s]+(.*)", re.IGNORECASE | re.DOTALL),
    # Generic "Answer:" pattern - place last as it's most likely to overmatch
    re.compile(r"(?:^|\.\s|\?\s|\!\s)answer[:\s]+(.*)", re.IGNORECASE | re.DOTALL),
]

# Arbitrary length limit for the simple newline heuristic in extract_final_answer.
# Used to prevent capturing large subsequent paragraphs if a newline appears early.
_MAX_LEN_BEFORE_NEWLINE_HEURISTIC: int = 150


def extract_structured_response(response_text: str) -> Optional[str]:
    """
    Attempts to parse structured JSON response and extract the final answer.

    Args:
        response_text: The structured JSON response text.

    Returns:
        The extracted final answer if JSON parsing is successful, otherwise None.
    """
    structured_data = safe_json_parse(response_text)
    if structured_data:
        final_answer = structured_data.get("final_answer", None)
        if final_answer:
            logger.info("Successfully extracted final answer from structured JSON.")
            return final_answer.strip()
    return None


def extract_final_answer(response_text: str) -> Optional[str]:
    # First attempt structured JSON parsing
    structured_answer = extract_structured_response(response_text)
    if structured_answer:
        return structured_answer

    """
    Attempts to extract the final answer segment from a model's response text.

    Uses a predefined list of regular expression patterns (`FINAL_ANSWER_PATTERNS`)
    to identify keywords indicating a final answer (e.g., "Final Answer:", "Answer:").
    It returns the text following the first matched pattern.

    A simple heuristic is applied to truncate the extracted text at the first
    newline character if it occurs within a certain limit (`_MAX_LEN_BEFORE_NEWLINE_HEURISTIC`),
    aiming to isolate the answer itself from subsequent explanations.

    Note:
        This function relies on simple string patterns and heuristics. It may fail
        if the model uses different phrasing, complex formatting, or does not
        explicitly label the final answer. More robust methods (e.g., advanced
        regex, NLP techniques, dedicated LLM calls) might be necessary for
        higher accuracy, as mentioned in the enhancement plan.

    Args:
        response_text: The full text content generated by the model.

    Returns:
        The extracted final answer as a string, stripped of leading/trailing
        whitespace, or None if no pattern matches or the input is empty.
    """
    if not response_text:
        return None

    # Iterate through patterns to find the first match
    # Check patterns in order
    for i, pattern in enumerate(FINAL_ANSWER_PATTERNS):
        match = pattern.search(response_text)
        if match:
            # Extract the matched group (group 1 for keyword patterns, group 1 for $$)
            extracted: str = match.group(1).strip()

            # If the pattern was the LaTeX one ($$), we likely want the whole matched content.
            # For keyword patterns, apply the newline heuristic.
            is_latex_pattern = (
                pattern.pattern == r"\$\$(.*?)\$\$"
            )  # Check if it's the LaTeX pattern

            if not is_latex_pattern:
                # Improved heuristic: Allow multi-line answers if enclosed in markdown or LaTeX
                markdown_or_latex = re.match(
                    r"(\*\*.*?\*\*|\\boxed\{.*?\}|^\$\$.*?\$\$)", extracted, re.DOTALL
                )
                if not markdown_or_latex:
                    # Extract until a clear delimiter (period, double newline, markdown heading, or end of text)
                    delimiter_match = re.search(r"(\.\s|\n\n|#+\s|$)", extracted)
                    if delimiter_match:
                        end_index = delimiter_match.start()
                        extracted = extracted[:end_index].strip()
                        logger.debug(
                            "Applying improved delimiter-based truncation heuristic."
                        )

            logger.info(
                "Successfully extracted final answer using fallback regex pattern index %d: %s. Extracted answer: '%s'",
                i,
                pattern.pattern,
                extracted,
            )
            return extracted

    # Enhanced logging for extraction failure
    logger.warning(
        "Failed to extract final answer. Patterns attempted: %s. Response text: '%s'",
        [p.pattern for p in FINAL_ANSWER_PATTERNS],
        response_text[:200] + "..." if len(response_text) > 200 else response_text,
    )
    return None


def normalize_text_formats(text: Optional[str]) -> Optional[str]:
    """
    Performs basic text normalization on a given string.

    Steps include:
    1.  Unicode Normalization (NFC form).
    2.  Replacing sequences of multiple whitespace characters (spaces, tabs,
        newlines, etc.) with a single space.
    3.  Stripping leading and trailing whitespace from the result.

    Note:
        This function currently does *not* handle specific markup like LaTeX or
        MathML. Such normalization would require dedicated libraries (e.g., SymPy)
        and should be implemented as part of the enhancement plan if needed,
        likely during the answer verification stage in postprocessing rather
        than general text normalization here.

    Args:
        text: The input string to normalize, or None.

    Returns:
        The normalized string, or None if the input `text` was None.
    """
    if text is None:
        return None

    # 1. Unicode normalization (NFC is common, combines characters and accents)
    normalized_text: str = unicodedata.normalize("NFC", text)

    # 2. Replace multiple whitespace characters (space, tab, newline, etc.) with a single space
    whitespace_normalized_text: str = re.sub(r"\s+", " ", normalized_text)

    # 3. Strip leading/trailing whitespace
    stripped_text: str = whitespace_normalized_text.strip()

    return stripped_text


# --- Additional Functionality: LaTeX Math Notation Conversion ---
# Precompiled regex patterns for performance
INLINE_MATH_PATTERN = re.compile(r"(?<!\\)\\\((.+?)\\\)", flags=re.DOTALL)
DISPLAY_MATH_PATTERN = re.compile(r"(?<!\\)\\\[(.+?)\\\]", flags=re.DOTALL)


def convert_math_notation(text: Optional[str]) -> Optional[str]:
    """
    Convert LaTeX math notation to standardized format for Jupyter notebooks or similar environments.

    Args:
        text (str): Input text containing LaTeX math notation.

    Returns:
        str: Text with standardized LaTeX math notation.
    """
    if not text:
        return text

    # Convert inline math \( ... \) to $...$
    text = INLINE_MATH_PATTERN.sub(r"$\1$", text)

    # Convert display math \[ ... \] to $$...$$
    text = DISPLAY_MATH_PATTERN.sub(r"$$\1$$", text)

    return text


if __name__ == "__main__":
    # Setup basic logging for testing if run directly
    logging.basicConfig(level=logging.INFO)
    logger.info("\n--- Testing: Extract Final Answer ---")

    test_cases = {
        "Keyword '**Answer:**'": ("Calculation complete. **Answer:** 42", "42"),
        "Keyword '**Conclusion:**'": (
            "Analysis done. **Conclusion:** The result is 3.14",
            "The result is 3.14",
        ),
        "Keyword '**Exact Answer:**'": (
            "Final computation. **Exact Answer:** x = 7",
            "x = 7",
        ),
        "LaTeX boxed notation": ("The solution is \\boxed{y = mx + c}", "y = mx + c"),
        "Keyword 'Final Answer'": ("Blah blah. Final Answer: x = 5", "x = 5"),
        "Keyword 'The final answer is' + newline": (
            "Calc y=10. The final answer is: y = 10 \n This is because...",
            "y = 10",
        ),
        "Keyword 'Answer'": ("Let z = 3. Answer: z=3", "z=3"),
        "Keyword 'Solution'": ("The steps lead to Solution: a+b=c", "a+b=c"),
        "Keyword 'Result'": ("After calculation, Result: 123.45", "123.45"),
        "LaTeX $$": ("Some text $$ E=mc^2 $$ and more text.", "E=mc^2"),
        "LaTeX $$ multi-line": (
            "Preamble $$\n a^2 + b^2 = c^2 \n$$ Postamble.",
            "a^2 + b^2 = c^2",
        ),
        "No Keyword": ("The value is approximately 42.", None),
        "Empty Input": ("", None),
        "Keyword only": ("Final Answer:", ""),
        "LaTeX empty": ("Text $$ $$ more text.", ""),
    }

    for name, (input_text, expected_output) in test_cases.items():
        extracted = extract_final_answer(input_text)
        status = "PASS" if extracted == expected_output else "FAIL"
        logger.info(f"Test '{name}': {status}")
        logger.debug(f"  Input: '{input_text}'")
        logger.info(f"  Output: '{extracted}' (Expected: '{expected_output}')")
        if status == "FAIL":
            logger.error(f"  MISMATCH FOUND for test '{name}'!")

    logger.info("\n--- Testing: Text Normalization ---")
    print("\n--- Text Normalization ---")
    test_norm_1 = "  Extra   spaces\nand\ttabs  "
    test_norm_2 = "Already clean."
    test_norm_3 = None
    print(f"'{test_norm_1}' -> '{normalize_text_formats(test_norm_1)}'")
    print(f"'{test_norm_2}' -> '{normalize_text_formats(test_norm_2)}'")
    print(f"'{test_norm_3}' -> '{normalize_text_formats(test_norm_3)}'")
    print(f"'{test_norm_3}' -> '{normalize_text_formats(test_norm_3)}'")
